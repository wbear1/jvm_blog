# 神秘的30s

线上某个项目出现kafka lag过大的问题，经过排查发现，提交consumer offset的线程出现了饥饿。大致做法如下代码所示：
```java
import java.util.concurrent.TimeUnit;

public class TestStarvationWithSync {

    static volatile Object obj = new Object();

    public static void main(String[] args) throws InterruptedException {
        LongTask longTask = new LongTask("long-task");
        longTask.start();

        ShortTask shortTask = new ShortTask("short-task");
        shortTask.start();

        TimeUnit.MINUTES.sleep(30);
    }

    static class LongTask extends Thread {

        public LongTask(String name) {
            super(name);
        }

        @Override
        public void run() {
            try {
                while (true) {
                    synchronized (obj) {
			            TimeUnit.SECONDS.sleep(1);
                    }
                }
            } catch (Throwable e) {
                e.printStackTrace();
            }
        }
    }

    static class ShortTask extends Thread {

        public ShortTask(String name) {
            super(name);
        }

        long lastTs = 0;

        @Override
        public void run() {
            while (true) {
                try {
                    synchronized (obj) {
                        long now = System.currentTimeMillis();
                        if (lastTs > 0) {
                            //从第二次开始，打印2次执行行之间的时间间隔
                            System.out.println(now - lastTs);
                        }
                        lastTs = now;
                    }
                    TimeUnit.MILLISECONDS.sleep(50);
                } catch (Throwable e) {
                    e.printStackTrace();
                }
            }
        }
    }

}
```

这里暂且不讨论其写法的合理性。比较容易发现这种写法会导致short-task线程会出现饥饿现象，具体了解下synchronized的原理就清楚了，关于synchronized的偏向锁、轻量级锁到重量级锁的演变过程，网上相关资料有很多，这里也不展开讨论。

但是把这个程序运行之后，发现结果比较有趣，short-task任务每2次执行之间的时间间隔约等于30s。怀疑跟操作系统和虚拟化有关系，于是在不同的操作系统和虚拟化环境运行，结果如下：
![result](https://github.com/wbear1/jvm_blog/blob/master/img/30s/result.png)

其中aws vm、azure vm、envision vm和ali vm均为centos的虚拟机，windows和mac为个人笔记本，前面4种虚拟机都有明显的规律。

同时，写一个c语言版本的类似程序，执行gcc mutex.c -o mutex -lpthread编译。结果却并未呈现上述现象。
```
#include <stdio.h>
#include <pthread.h>
#include <unistd.h>
#include <stdlib.h>
#include <sys/time.h>
 
pthread_mutex_t mutex;
static int lastTs = 0;
 
void func1(void* args)
{
    while(1)
    {
        pthread_mutex_lock(&mutex);
        sleep(1);
        pthread_mutex_unlock(&mutex);
    }
}

void func2(void * args)
{
	while(1)
	{
		pthread_mutex_lock(&mutex);
     		struct timeval tv;    
     		gettimeofday(&tv,NULL);
     		int now = tv.tv_sec;
		if(lastTs > 0)
			printf("%d\n", (tv.tv_sec - lastTs));
		lastTs = now;
		pthread_mutex_unlock(&mutex);
		usleep(50000);
	}
}
 
int main()
{
    pthread_t pid1, pid2;
    pthread_mutex_init(&mutex, NULL);
 
    if(pthread_create(&pid1, NULL, func1, NULL))
    {
        return -1;
    }
 
    if(pthread_create(&pid2, NULL, func2, NULL))
    {
        return -1;
    }
 
    sleep(1800);
 
    return 0;
}
```

最后，看来下一步需要研究synchronized源码，方能理解这神秘的30s了。